# AI生成コードはなぜ再現できないのか

## フォレンジック視点で理解するLLMコーディングの本質

## はじめに

AIでコードを書いていると、次のような経験はありませんか。

- 同じプロンプトなのに違うコードが出る
- バグを再現できない
- もう一度生成させると直ってしまう

これは"たまたま"ではありません。LLMの性質です。

---

## 従来のデバッグ

    コード → 実行 → 再現

再現できれば原因特定が可能でした。

---

## AI開発のデバッグ

    プロンプト
    モデル状態
    外部コンテキスト
    ツール実行
    確率生成
    → コード

同じ条件が揃いません。

---

## なぜ再現できないのか

### 1. 確率生成（temperature）

LLMは非決定的です。次のトークンが確率で選ばれます。

### 2. コンテキスト依存

- 開いているファイル
- 直前の会話
- IDEの状態

すべて入力に影響します。

### 3. ツール呼び出し

検索、テスト実行、ファイル読み込みなどの結果も入力になります。

---

## フォレンジック問題

つまり、出力だけでは原因を特定できません。

必要なのは以下の情報です。

- プロンプト
- 応答
- ツール実行履歴

---

## 解決の方向性

AI開発では「コード」ではなく「生成過程」を記録する必要があります。

背景記事は「AIがコードを書く時代、Gitだけでは監査できない」です。
